{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to predict survival of Titanic passengers using Python and its libraries. Many models will be covered with fine-tuned hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lib.data_utils import load_Titanic, create_submission\n",
    "from sklearn.preprocessing import scale, LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.827377' '1' '-0.59759' '0.432793' '-0.47367' '-0.50244' '2']\n",
      " ['-1.56610' '0' '0.632604' '0.432793' '-0.47367' '0.786845' '0']\n",
      " ['0.827377' '0' '-0.29004' '-0.47454' '-0.47367' '-0.48885' '2']\n",
      " ['-1.56610' '0' '0.401941' '0.432793' '-0.47367' '0.420730' '2']\n",
      " ['0.827377' '1' '0.401941' '-0.47454' '-0.47367' '-0.48633' '2']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chase\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype <U8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "x_train, y_train = load_Titanic()\n",
    "\n",
    "# preprocessing: standardize numeric, encode categorical\n",
    "x_train[:,[0,2,3,4,5]] = scale(x_train[:,[0,2,3,4,5]])\n",
    "for i in [1,6]:\n",
    "    x_train[:,i] = LabelEncoder().fit_transform(x_train[:,i])\n",
    "\n",
    "# see if it works well\n",
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use random search to fine-tune the hyperparameters of kNN and get the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'leaf_size': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 50]), 'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]), 'p': array([1, 2, 3, 4, 5])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the range of hyperparameters\n",
    "param_distributions = {'n_neighbors': np.array(np.linspace(1,15,15), dtype=np.int),\n",
    "                       'p': np.array(np.linspace(1,5,5), dtype=np.int),\n",
    "                       'leaf_size': np.array(np.linspace(10,50,40), dtype=np.int)}\n",
    "# initialize the random search\n",
    "random_search = RandomizedSearchCV(estimator=KNeighborsClassifier(),\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter=30,\n",
    "                                   cv=10,\n",
    "                                   verbose=1)\n",
    "# start searching\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the searching, we see the hyperparameters and accuracy of the best model, and keep the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 24, 'n_neighbors': 6, 'p': 1}\n",
      "Best accuracy:  0.824915824916\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=24, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=1,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)\n",
    "print('Best accuracy: ', random_search.best_score_)\n",
    "print(random_search.best_estimator_)\n",
    "nn = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's no hyperparameters for Gaussian Naive Bayes, there's no need to do random search, so we just fit the data, and see the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.792368125701\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(x_train.astype(np.float), y_train.astype(np.float))\n",
    "print('Training accuracy: ', nb.score(x_train.astype(np.float), y_train.astype(np.float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Random Forest has been run on R with 0.78 test accuracy, we train here again with hyperparameters fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=30, n_jobs=1,\n",
       "          param_distributions={'min_impurity_decrease': array([ 0.     ,  0.00526,  0.01053,  0.01579,  0.02105,  0.02632,\n",
       "        0.03158,  0.03684,  0.04211,  0.04737,  0.05263,  0.05789,\n",
       "        0.06316,  0.06842,  0.07368,  0.07895,  0.08421,  0.08947,\n",
       "        0.09474,  0.1    ]), 'n_estimators': array([ ...es': array([1, 2, 3, 4, 5, 6, 7]), 'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the range of hyperparameters\n",
    "param_distributions = {'n_estimators': np.array(np.arange(10,501), dtype=np.int),\n",
    "                       'max_features': np.array(np.linspace(1,7,7), dtype=np.int),\n",
    "                       'min_samples_split': np.array(np.linspace(2,10,9), dtype=np.int),\n",
    "                       'min_samples_leaf': np.array(np.linspace(1,10,10), dtype=np.int),\n",
    "                       'min_impurity_decrease': np.linspace(0,0.1,20)}\n",
    "# initialize the random search\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter=30,\n",
    "                                   cv=10,\n",
    "                                   verbose=1)\n",
    "# start searching\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the searching, we see the hyperparameters and accuracy of the best model, and keep the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_impurity_decrease': 0.0, 'n_estimators': 16, 'min_samples_leaf': 4, 'max_features': 7, 'min_samples_split': 4}\n",
      "Best accuracy:  0.849607182941\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=16, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)\n",
    "print('Best accuracy: ', random_search.best_score_)\n",
    "print(random_search.best_estimator_)\n",
    "rf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use random search to fine-tune the hyperparameters of SVM and get the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'gamma': array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]), 'C': array([ 0.1    ,  0.35789,  0.61579,  0.87368,  1.13158,  1.38947,\n",
       "        1.64737,  1.90526,  2.16316,  2.42105,  2.67895,  2.93684,\n",
       "        3.19474,  3.45263,  3.71053,  3.96842,  4.22632,  4.48421,\n",
       "        4.74211,  5.     ]), 'tol': array([ 0.0001,  0.0012,  0.0023,  0.0034,  0.0045,  0.0056,  0.0067,\n",
       "        0.0078,  0.0089,  0.01  ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the range of hyperparameters\n",
    "param_distributions = {'C': np.linspace(0.1,5,20),\n",
    "                       'gamma': np.linspace(0.1,1,10),\n",
    "                       'tol': np.linspace(1e-4,1e-2,10)}\n",
    "# initialize the random search\n",
    "random_search = RandomizedSearchCV(estimator=SVC(),\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter=100,\n",
    "                                   cv=10,\n",
    "                                   verbose=1)\n",
    "# start searching\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the searching, we see the hyperparameters and accuracy of the best model, and keep the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.10000000000000001, 'tol': 0.01, 'C': 2.9368421052631581}\n",
      "Best accuracy:  0.829405162738\n",
      "SVC(C=2.9368421052631581, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.10000000000000001,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.01, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)\n",
    "print('Best accuracy: ', random_search.best_score_)\n",
    "print(random_search.best_estimator_)\n",
    "svm = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have more flexibility, we use Keras instead of Multilayer Perceptron in scikit_learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is used to generate submission file for Kaggle competition using trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chase\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype <U8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# read the test data and preprocess\n",
    "x_test = load_Titanic(filename='../data/test - processed.csv', test=True)\n",
    "x_test[:,[0,2,3,4,5]] = scale(x_test[:,[0,2,3,4,5]])\n",
    "for i in [1,6]:\n",
    "    x_test[:,i] = LabelEncoder().fit_transform(x_test[:,i])\n",
    "    \n",
    "# create submission file\n",
    "create_submission(svm, x_test, '../submission/submission_svm_ft.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
